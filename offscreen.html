<!DOCTYPE html>
<html>
<head>
  <title>Explanium AI Processor</title>
</head>
<body>
  <script type="module">
    console.log('[Offscreen] Script start.');
    console.log('[Offscreen] Document script loaded.');

    // Import the Transformers.js library
    import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.1';

    // --- State ---
    let modelPipeline = null;

    // --- Core Functions ---

    async function initializeModel() {
        console.log('[Offscreen] Initializing text-classification pipeline with a smaller model for testing...');
        // Disable local model checks for simplified web worker environment
        env.allowLocalModels = false;
        
        try {
            // Use a smaller, more reliable model for debugging the loading process
            modelPipeline = await pipeline('text-classification', 'Xenova/distilbert-base-uncased-finetuned-sst-2-english', {
                progress_callback: (progress) => {
                    console.log('[Offscreen] Model loading progress:', progress);
                }
            });
            console.log('[Offscreen] Pipeline initialized successfully!');
            return { success: true };
        } catch (error) {
            console.error('[Offscreen] Pipeline initialization failed:', error);
            return { success: false, error: error.message };
        }
    }

    async function generateExplanation(text) {
        if (!modelPipeline) {
            console.error('[Offscreen] Attempted to generate explanation before model was initialized.');
            return { success: false, error: 'Pipeline not initialized.' };
        }
        
        console.log(`[Offscreen] Generating classification for: "${text.substring(0, 50)}..."`);
        // Note: This model does classification, not generation. The output will be different.
        // The goal here is just to test the pipeline.
        const prompt = text;

        try {
            const result = await modelPipeline(prompt);

            const classification = JSON.stringify(result);
            console.log(`[Offscreen] Classification generated successfully.`);
            return { success: true, explanation: `Test successful. Classification: ${classification}` };
        } catch (error) {
            console.error('[Offscreen] Error during text classification:', error);
            return { success: false, error: error.message };
        }
    }

    // --- Message Handling ---

    console.log('[Offscreen] Attaching message listener...');
    chrome.runtime.onMessage.addListener((request, sender, sendResponse) => {
        console.log(`[Offscreen] Message received: ${request.type}`);
        let isAsync = false;

        switch (request.type) {
            case 'ACTIVATE_MODEL':
                isAsync = true;
                initializeModel().then(sendResponse);
                break;
            
            case 'EXPLAIN_TEXT':
                isAsync = true;
                generateExplanation(request.text).then(sendResponse);
                break;

            default:
                // We shouldn't get other messages, but good to log.
                console.warn(`[Offscreen] Received unknown message type: ${request.type}`);
                break;
        }

        // Return true to indicate we will respond asynchronously.
        return isAsync;
    });

    console.log('[Offscreen] Script initialized. Sending ready signal to background.');
    // HANDSHAKE: Signal to the background script that the offscreen document is loaded and ready.
    chrome.runtime.sendMessage({ type: 'offscreen-ready' });

  </script>
</body>
</html> 